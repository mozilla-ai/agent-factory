{
  "agent_code": "# agent.py\n\nimport os\nfrom dotenv import load_dotenv\nfrom any_agent import AgentConfig, AnyAgent\nfrom any_agent.config import MCPStdio\nfrom pydantic import BaseModel, Field\nfrom fire import Fire\n\n# ---- local / any-agent built-in tools ----\nfrom tools.extract_text_from_url import extract_text_from_url\nfrom tools.generate_podcast_script_with_llm import generate_podcast_script_with_llm\n\nload_dotenv()\n\n# ========== Structured output definition ==========\nclass StructuredOutput(BaseModel):\n    url: str = Field(..., description=\"The original webpage URL supplied by the user.\")\n    num_hosts: int = Field(..., description=\"Number of podcast hosts / speakers requested.\")\n    script_text: str = Field(..., description=\"The full podcast script that was generated.\")\n    audio_file_path: str = Field(..., description=\"Filesystem path (inside ELEVENLABS_OUTPUT_DIR) or URL pointing to the generated multi-speaker podcast MP3 file.\")\n\n\n# ========== System (Multi-step) Instructions ==========\nINSTRUCTIONS = \"\"\"\nYou are an autonomous assistant that turns any public web article into a polished multi-speaker podcast in three clear stages.\n\nStep-by-step workflow you MUST follow:\n1. CONTENT EXTRACTION — Receive a URL from the user and call the `extract_text_from_url` tool to fetch and clean the main textual content of the page. If extraction fails, stop and return a helpful error.\n2. SCRIPT WRITING — With the extracted text, invoke `generate_podcast_script_with_llm`, passing the user-requested number of hosts so the script alternates dialogue between distinct speakers (labelled **Host 1**, **Host 2**, etc.). Keep the script engaging, conversational and less than ~2,000 words.\n3. AUDIO GENERATION — Send the entire finished script to the `generate_audio_script` tool from the ElevenLabs MCP server. A single call should return a high-quality MP3 that already contains all voices. Use the default voice mapping unless the user provides explicit voice IDs.\n\nUpon completing these steps, respond ONLY with a JSON object that conforms exactly to the StructuredOutput schema (do NOT add any extra keys). Ensure `audio_file_path` is whatever location or URL the ElevenLabs server returns for the generated file.\n\"\"\"\n\n# ========== Tools definition ==========\nTOOLS = [\n    # local Python utility tools\n    extract_text_from_url,\n    generate_podcast_script_with_llm,\n    # ElevenLabs MCP (text-to-speech)\n    MCPStdio(\n        command=\"docker\",\n        args=[\n            \"run\",\n            \"-i\",\n            \"--rm\",\n            \"-e\",\n            \"ELEVENLABS_API_KEY\",\n            \"mcp/elevenlabs\",\n        ],\n        env={\n            \"ELEVENLABS_API_KEY\": os.getenv(\"ELEVENLABS_API_KEY\"),  # required\n            # Optional overrides – read from environment if present\n            \"ELEVENLABS_VOICE_ID\": os.getenv(\"ELEVENLABS_VOICE_ID\", \"\"),\n            \"ELEVENLABS_MODEL_ID\": os.getenv(\"ELEVENLABS_MODEL_ID\", \"\"),\n            \"ELEVENLABS_OUTPUT_DIR\": os.getenv(\"ELEVENLABS_OUTPUT_DIR\", \"output\"),\n        },\n        # use the minimum necessary ElevenLabs tool\n        tools=[\n            \"generate_audio_script\",\n        ],\n    ),\n]\n\n# Build the agent\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"o3\",\n        instructions=INSTRUCTIONS,\n        tools=TOOLS,\n        agent_args={\"output_type\": StructuredOutput},\n        model_args={\"tool_choice\": \"required\"},\n    ),\n)\n\n\ndef run_agent(url: str, num_hosts: int = 2):\n    \"\"\"Create a multi-speaker podcast from the given webpage URL.\"\"\"\n    input_prompt = (\n        f\"Create an audio podcast with {num_hosts} hosts from this webpage: {url}\\n\"\n        \"Return only structured JSON per specification.\"\n    )\n    # pass num_hosts via prompt so the agent uses it when calling tools\n    agent_trace = agent.run(prompt=input_prompt)\n\n    # Persist the full execution trace for evaluation/debugging\n    with open(\"generated_workflows/latest/agent_eval_trace.json\", \"w\", encoding=\"utf-8\") as f:\n        f.write(agent_trace.model_dump_json(indent=2))\n\n    return agent_trace.final_output\n\n\nif __name__ == \"__main__\":\n    Fire(run_agent)\n",
  "run_instructions": "## Setup & Run Instructions\n\n1. Clone the project and **cd** into its root directory.\n\n2. Create a Python 3.11 environment (using **mamba**, conda-forge channel recommended):\n\n```bash\nmamba create -n anyagent-podcast python=3.11 -c conda-forge\nmamba activate anyagent-podcast\n```\n\n3. Create a `.env` file in the project root containing your secrets:\n\n```dotenv\n# OpenAI or other LLM provider key (required by any-agent / OpenAI backend)\nOPENAI_API_KEY=\"sk-...\"\n\n# ElevenLabs Text-to-Speech key (required) \nELEVENLABS_API_KEY=\"elevenlabs-...\"  \n\n# Optional: customise voice / output directory\n# ELEVENLABS_VOICE_ID=\"voice-abc123\"\n# ELEVENLABS_MODEL_ID=\"eleven_multilingual_v2\"\n# ELEVENLABS_OUTPUT_DIR=\"output\"\n```\n\n4. Install Python dependencies from `requirements.txt`:\n\n```bash\npip install -r requirements.txt\n```\n\n5. Ensure **Docker** is running (the ElevenLabs MCP server is executed in a short-lived Docker container).\n\n6. Run the agent:\n\n```bash\npython agent.py run-agent --url \"https://example.com/interesting-article\" --num_hosts 3\n```\n\nThe command prints a JSON object with the podcast script and a path/URL to the generated MP3 file. A full execution trace is saved to `generated_workflows/latest/agent_eval_trace.json` for inspection or evaluation.\n\n> **Note:** The ElevenLabs container stores the resulting MP3 under the path specified by `ELEVENLABS_OUTPUT_DIR` (default: `output/` inside the container and then bind-mounted back). Make sure that directory exists or point the env var elsewhere. Docker must be able to pull the `mcp/elevenlabs` image on first run.\n",
  "dependencies": "any-agent[all]\npython-dotenv\nfire\npydantic>=2\nrequests\nbeautifulsoup4\nlitellm"
}
