{
  "agent_code": "# agent.py\n\nimport os\nfrom typing import List\n\nfrom dotenv import load_dotenv\nfrom any_agent import AnyAgent, AgentConfig\nfrom any_agent.config import MCPStdio\nfrom pydantic import BaseModel, Field\nfrom fire import Fire\n\n# ====== Import tool functions ======\nfrom tools.extract_text_from_url import extract_text_from_url\nfrom tools.generate_podcast_script_with_llm import generate_podcast_script_with_llm\nfrom tools.combine_mp3_files_for_podcast import combine_mp3_files_for_podcast\n\nload_dotenv()\n\n# ========= Structured output definition =========\nclass PodcastGenerationOutput(BaseModel):\n    \"\"\"Structured response returned by the agent once the podcast is generated.\"\"\"\n\n    podcast_path: str = Field(..., description=\"Relative path to the final combined podcast MP3 file.\")\n    script_text: str = Field(..., description=\"The full podcast script that was used for voice generation.\")\n    voices_used: List[str] = Field(..., description=\"List of voice IDs that were used, in the order they appeared in the script.\")\n\n\n# ========= System (Multi-step) Instructions =========\nINSTRUCTIONS = \"\"\"\nYou are an AI assistant that turns any webpage into a multi-speaker audio podcast.  \nFollow this four-step workflow strictly:\n\n1. Extract   \n   • Use the `extract_text_from_url` tool to fetch the main readable text from the provided URL.  \n   • Remove boilerplate (navigation, ads, footer) and keep the core article.\n\n2. Script   \n   • Write a lively podcast script with the `generate_podcast_script_with_llm` tool.  \n   • Number of hosts = number of voice IDs provided by the user (minimum 2; default 2 if none supplied).  \n   • The script must alternate between hosts, be engaging, and cover the entire article content concisely.\n\n3. Voice   \n   • Convert the script into audio with the `generate_audio_script` tool from the ElevenLabs MCP server.  \n   • Provide a JSON payload of the form:  \n     `{ \"script\": [ {\"text\": \"...\", \"voice_id\": \"<voice_id_1>\", \"actor\": \"Host-1\"}, ... ] }`  \n   • Map each host to the corresponding `voice_id` in round-robin order if hosts > voices supplied.\n\n4. Combine   \n   • Merge all returned MP3 segments into a single podcast episode using `combine_mp3_files_for_podcast`.  \n   • Name the output file `podcast_episode.mp3` and save it in the current working directory.\n\nReturn ONLY a JSON object that conforms to PodcastGenerationOutput.  \nDo NOT include any additional keys or text outside the JSON.\n\"\"\"\n\n# ========= Tools definition =========\nTOOLS = [\n    extract_text_from_url,\n    generate_podcast_script_with_llm,\n    # ElevenLabs MCP server – only the tool we need (generate_audio_script)\n    MCPStdio(\n        command=\"docker\",\n        args=[\n            \"run\",\n            \"-i\",\n            \"--rm\",\n            \"-e\",\n            \"ELEVENLABS_API_KEY\",\n            \"mcp/elevenlabs\",\n        ],\n        env={\n            \"ELEVENLABS_API_KEY\": os.getenv(\"ELEVENLABS_API_KEY\"),\n        },\n        tools=[\"generate_audio_script\"],\n    ),\n    combine_mp3_files_for_podcast,\n]\n\n# ========= Agent definition =========\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"o3\",\n        instructions=INSTRUCTIONS,\n        tools=TOOLS,\n        output_type=PodcastGenerationOutput,\n        # Require the model to invoke tools when needed\n        model_args={\"tool_choice\": \"required\"},\n    ),\n)\n\n# ========= Runner =========\nPROMPT_TEMPLATE = (\n    \"Create a multi-speaker podcast from this URL: {url}. \"\n    \"Use these voice IDs (comma-separated, leave blank for defaults): {voice_ids}.\"\n)\n\ndef run_agent(url: str, voice_ids: str = \"\") -> PodcastGenerationOutput:  # noqa: D401\n    \"\"\"Generate an audio podcast from the given URL.\n\n    Args:\n        url: Webpage URL to turn into a podcast.\n        voice_ids: Comma-separated ElevenLabs voice IDs (optional).\n    Returns:\n        PodcastGenerationOutput structured object.\n    \"\"\"\n    # Build prompt for the agent\n    input_prompt = PROMPT_TEMPLATE.format(url=url, voice_ids=voice_ids.strip())\n\n    agent_trace = agent.run(prompt=input_prompt, max_turns=20)\n\n    # Persist trace for evaluation\n    os.makedirs(\"generated_workflows/latest\", exist_ok=True)\n    with open(\"generated_workflows/latest/agent_eval_trace.json\", \"w\", encoding=\"utf-8\") as f:\n        f.write(agent_trace.model_dump_json(indent=2))\n\n    # Return the structured final output\n    return agent_trace.final_output\n\n\nif __name__ == \"__main__\":\n    Fire(run_agent)\n",
  "run_instructions": "## Setup & Run Instructions\n\n1. **Clone the repository / place the files** so that `agent.py`, the `tools/` directory and `generated_workflows/latest/` directory are in the same root.\n\n2. **Create a `.env` file** in the project root with these environment variables:\n\n```dotenv\n# OpenAI model access\nOPENAI_API_KEY=your_openai_key\n\n# ElevenLabs text-to-speech\nELEVENLABS_API_KEY=your_elevenlabs_key\n```\n\n*(If you prefer specific ElevenLabs voices, pass them via the CLI when running the agent.)*\n\n3. **Install dependencies & run the agent** (requires Python 3.11):\n\n```bash\nuv run --with-requirements generated_workflows/latest/requirements.txt --python 3.11 \\\n  python generated_workflows/latest/agent.py --url \"https://example.com/interesting-article\" --voice_ids \"voiceId1,voiceId2\"\n```\n\nThe script will:\n1. Extract the article text.  \n2. Write a two-host podcast script.  \n3. Synthesise the dialogue using ElevenLabs voices.  \n4. Merge the audio into `podcast_episode.mp3` in the current directory.  \n5. Save an execution trace at `generated_workflows/latest/agent_eval_trace.json` for evaluation.\n",
  "dependencies": "any-agent[all]==0.20.0\npython-dotenv\nfire\nbeautifulsoup4\nrequests\nlxml"
}
