{
  "agent_code": "# agent.py\n\nimport os\nfrom dotenv import load_dotenv\nfrom any_agent import AgentConfig, AnyAgent\nfrom any_agent.config import MCPStdio\nfrom pydantic import BaseModel, Field\nfrom fire import Fire\n\n# === Local / built-in tools ===\nfrom tools.extract_text_from_url import extract_text_from_url\nfrom tools.generate_podcast_script_with_llm import generate_podcast_script_with_llm\n# (We will rely on the ElevenLabs MCP server for text-to-speech)\n\nload_dotenv()\n\n# ========== Structured output definition ==========\nclass PodcastOutput(BaseModel):\n    url: str = Field(..., description=\"The original webpage URL.\")\n    num_speakers: int = Field(..., description=\"Number of speakers in the generated podcast.\")\n    podcast_script: str = Field(..., description=\"The full podcast script with speaker labels.\")\n    audio_file_path: str = Field(..., description=\"Filesystem path (or URL) to the generated podcast MP3 audio file.\")\n\n\n# ========== System (Multi-step) Instructions ==========\nINSTRUCTIONS = \"\"\"\nYou are an expert media production assistant.  Follow this exact multi-step workflow to turn an input webpage\ninto a multi-speaker podcast:\n\nStep 1 ‑ Extract text.\n    • Use the tool `extract_text_from_url` on the provided URL.\n    • Return ONLY the primary readable content (ignore menus, ads, navigation, etc.).\n\nStep 2 ‑ Write a podcast script.\n    • Use `generate_podcast_script_with_llm`.\n    • The number of hosts MUST equal the `num_speakers` value supplied by the user (default 2).\n    • Clearly label each host line (e.g. Host 1:, Host 2: …).\n    • The script should be lively, conversational and cover all key points from the article.\n\nStep 3 ‑ Generate audio with multiple voices.\n    • Call the ElevenLabs MCP tool `generate_audio_script`.\n    • Pass the full script in plain text. The tool will automatically allocate different voices for each labelled host.\n    • Wait until the audio job finishes and obtain the final MP3 file path returned by the tool.\n\nStep 4 ‑ Produce final structured result.\n    • Return a JSON object conforming to the PodcastOutput schema containing:\n         – url (original URL)\n         – num_speakers (integer)\n         – podcast_script (full script)\n         – audio_file_path (path/URL from Step 3)\n    • Do NOT output anything that does not belong in the JSON schema.\n\"\"\"\n\n# ========== Tools definition ==========\nTOOLS = [\n    # Local python-function tools\n    extract_text_from_url,\n    generate_podcast_script_with_llm,\n    # MCP server for ElevenLabs TTS\n    MCPStdio(\n        command=\"docker\",\n        args=[\n            \"run\",\n            \"-i\",\n            \"--rm\",\n            \"-e\",\n            \"ELEVENLABS_API_KEY\",\n            \"mcp/elevenlabs\",\n        ],\n        env={\n            \"ELEVENLABS_API_KEY\": os.getenv(\"ELEVENLABS_API_KEY\"),\n        },\n        tools=[\n            \"generate_audio_script\",  # only tool we need from this MCP server\n        ],\n    ),\n]\n\n# ========== Agent instance ==========\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"o3\",\n        instructions=INSTRUCTIONS,\n        tools=TOOLS,\n        output_type=PodcastOutput,\n        model_args={\"tool_choice\": \"required\"},\n    ),\n)\n\n# ========== CLI entry-point ==========\n\ndef run_agent(url: str, num_speakers: int = 2):\n    \"\"\"Generate a multi-speaker podcast from a webpage URL.\"\"\"\n    # Compose the user prompt that kicks off the workflow\n    input_prompt = (\n        \"Create a podcast with {n} speakers from this webpage URL: {u}. \"\n        \"Return the final result using the required JSON schema.\".format(n=num_speakers, u=url)\n    )\n\n    agent_trace = agent.run(prompt=input_prompt, max_turns=20)\n\n    # Persist the full trace for evaluation\n    with open(\"generated_workflows/latest/agent_eval_trace.json\", \"w\", encoding=\"utf-8\") as f:\n        f.write(agent_trace.model_dump_json(indent=2))\n\n    return agent_trace.final_output\n\n\nif __name__ == \"__main__\":\n    Fire(run_agent)\n",
  "run_instructions": "## Setup & Run Instructions\n\n1. **Create a virtual environment (optional but recommended)**\n\n```bash\npython3.11 -m venv .venv\nsource .venv/bin/activate\n```\n\n2. **Create a `.env` file** in the project root and add the following keys:\n\n```env\n# OpenAI / Azure-OpenAI key for any-agent to call the LLM\nOPENAI_API_KEY=YOUR_OPENAI_KEY_HERE\n\n# ElevenLabs key for text-to-speech\nELEVENLABS_API_KEY=YOUR_ELEVENLABS_KEY_HERE\n```\n\n3. **Install dependencies & run** using `uv` (ensures deterministic builds):\n\n```bash\nuv run --with-requirements generated_workflows/latest/requirements.txt --python 3.11 \\\n  python generated_workflows/latest/agent.py --url \"https://example.com\" --num_speakers 3\n```\n\nReplace the URL with any article you want converted into a podcast.\n\n\n",
  "dependencies": "any-agent[all]==0.20.0\npython-dotenv\nfire\nbeautifulsoup4\nrequests\nlitellm\n"
}
