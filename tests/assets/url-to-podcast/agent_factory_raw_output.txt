{
  "agent_code": "# agent.py\n\nimport os\nfrom dotenv import load_dotenv\nfrom any_agent import AgentConfig, AnyAgent\nfrom any_agent.config import MCPStdio\nfrom pydantic import BaseModel, Field\nfrom fire import Fire\n\n# ===== Import callable tools =====\nfrom tools.extract_text_from_url import extract_text_from_url\nfrom tools.generate_podcast_script_with_llm import generate_podcast_script_with_llm\n\nload_dotenv()\n\n# ========= Structured output definition =========\nclass StructuredOutput(BaseModel):\n    url: str = Field(..., description=\"The original webpage URL that was processed.\")\n    num_hosts: int = Field(..., description=\"Number of podcast hosts/speakers requested.\")\n    script: str = Field(..., description=\"The generated multi-speaker podcast script.\")\n    audio_file_path: str = Field(..., description=\"Local path (or URL) to the final narrated podcast audio file.\")\n\n\n# ========= System (Multi-step) Instructions =========\nINSTRUCTIONS = \"\"\"\nYou are an autonomous assistant that converts a webpage into a narrated, multi-speaker podcast.\nFollow these steps strictly:\n1. INPUT: You receive a webpage URL and an integer `num_hosts` specifying the number of podcast speakers.\n2. EXTRACTION: Call `extract_text_from_url` to fetch and clean the full textual content of the page.\n   • If the function returns an error (string beginning with \"Error\"), stop and return that error in `script`, leave `audio_file_path` blank.\n3. SCRIPT WRITING: Use `generate_podcast_script_with_llm` with `document_text=<extracted_text>` and `num_hosts=<num_hosts>` to craft an engaging dialogue.\n   • Ensure host lines are clearly labelled (e.g., \"Host 1:\", \"Host 2:\").\n4. TTS GENERATION: Invoke the ElevenLabs MCP tool `generate_audio_script`.\n   • Pass the entire script as a JSON string in the format: {\"script\": <SCRIPT_TEXT>}.\n   • Let ElevenLabs assign suitable default voices if `voice_id` is omitted.\n   • Capture the returned `job_id`.\n5. RETRIEVE AUDIO: Use `get_audio_file` with the `job_id` to download or locate the final MP3 file path.\n6. OUTPUT: Return a JSON object with these fields strictly matching the `StructuredOutput` model:\n   • url – the original URL\n   • num_hosts – the integer supplied by the user\n   • script – the complete podcast script text\n   • audio_file_path – path or URL of the generated MP3\nAlways follow the steps in order, call only the listed tools, and do not hallucinate tool outputs.\n\"\"\"\n\n# ========= Tools definition =========\nTOOLS = [\n    extract_text_from_url,\n    generate_podcast_script_with_llm,\n    # ElevenLabs MCP – only the two tools we need\n    MCPStdio(\n        command=\"docker\",\n        args=[\n            \"run\",\n            \"-i\",\n            \"--rm\",\n            \"-e\",\n            \"ELEVENLABS_API_KEY\",  # pass through the API key\n            \"mcp/elevenlabs\",\n        ],\n        env={\n            \"ELEVENLABS_API_KEY\": os.getenv(\"ELEVENLABS_API_KEY\"),\n        },\n        tools=[\n            \"generate_audio_script\",\n            \"get_audio_file\",\n        ],\n    ),\n]\n\n# ========= Agent creation =========\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"o3\",\n        instructions=INSTRUCTIONS,\n        tools=TOOLS,\n        agent_args={\"output_type\": StructuredOutput},\n        model_args={\"tool_choice\": \"required\"},\n    ),\n)\n\n# ========= CLI runner =========\n\ndef run_agent(url: str, num_hosts: int = 2):\n    \"\"\"Generate a narrated multi-speaker podcast from a webpage URL.\"\"\"\n    prompt_template = (\n        \"Create a {num_hosts}-speaker podcast from the content of this webpage: {url}. \"\n        \"Return the structured JSON as specified.\"\n    )\n    input_prompt = prompt_template.format(url=url, num_hosts=num_hosts)\n    agent_trace = agent.run(prompt=input_prompt)\n\n    # Save trace for evaluation\n    os.makedirs(\"generated_workflows/latest\", exist_ok=True)\n    with open(\"generated_workflows/latest/agent_eval_trace.json\", \"w\", encoding=\"utf-8\") as f:\n        f.write(agent_trace.model_dump_json(indent=2))\n\n    return agent_trace.final_output\n\n\nif __name__ == \"__main__\":\n    Fire(run_agent)\n",
  "run_instructions": "### Setup Instructions\n\n1. Clone the repository (or copy `agent.py` and the `tools/` directory).\n\n2. Create a `.env` file in the project root and add the required environment variables:\n\n```\nOPENAI_API_KEY=your_openai_api_key_here\nELEVENLABS_API_KEY=your_elevenlabs_api_key_here  # Obtain from https://elevenlabs.io\n```\n\n3. Create and activate the environment (Python 3.11) using mamba:\n\n```bash\nmamba create -n podcast-agent python=3.11 -y\nmamba activate podcast-agent\n```\n\n4. Install dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n5. Ensure Docker is installed and running (the ElevenLabs MCP server is executed in a Docker container).\n\n6. Run the agent:\n\n```bash\npython agent.py run-agent --url \"https://example.com/article\" --num_hosts 3\n```\n\nThe script will output a JSON object containing the podcast script and the path to the generated audio file, and create a trace file at `generated_workflows/latest/agent_eval_trace.json`.\n",
  "dependencies": "any-agent[all]\npython-dotenv\nbeautifulsoup4\nrequests\nfire\nlitellm"
}
