{
  "agent_code": "```python\n# agent.py\n\"\"\"\nAgent: Webpage Content Summarizer (Single-Agent, Multi-Step)\n-----------------------------------------------------------\nSummarizes text content from a given webpage URL using any-agent, OpenAI's GPT-4.1 model, and structured output via Pydantic.\n\"\"\"\n\nfrom any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import visit_webpage\nfrom pydantic import BaseModel, Field\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env\nload_dotenv()\n\n# === Pydantic model for structured output ===\nclass WebpageSummaryOutput(BaseModel):\n    url: str = Field(..., description=\"The original webpage URL that was summarized.\")\n    summary: str = Field(..., description=\"A concise summary of the main textual content from the webpage.\")\n\n# === Detailed Step-by-Step Agent Instructions ===\nINSTRUCTIONS = \"\"\"\nYou are an expert assistant whose task is to summarize text content from a webpage given its URL. Follow this precise workflow:\n\nStep 1: Receive the input URL from the user prompt.\nStep 2: Use the provided 'visit_webpage' tool to retrieve the text and main content from the given URL. Only use the content returned by the tool; do not hallucinate or use external information.\nStep 3: Read the webpage content carefully. Identify and focus on the main body text, skipping headers, footers, navigation, ads, and unrelated material.\nStep 4: Write a clear, concise summary (4-6 sentences) capturing the essential points and main arguments or information from the body text. Do not include a list of sections, metadata, or raw sentences; your summary should be human-readable and coherent.\nStep 5: Output your results as JSON with two fields:\n- 'url': the original webpage URL\n- 'summary': your generated summary\nYour output MUST match the schema given. Never return information not present in the visited webpage.\n\"\"\"\n\n# === Agent instantiation ===\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"gpt-4.1\",\n        instructions=INSTRUCTIONS,\n        tools=[\n            visit_webpage,\n        ],\n        agent_args={\n            \"output_type\": WebpageSummaryOutput,\n        },\n    ),\n)\n\n# === Sample agent run ===\nif __name__ == \"__main__\":\n    # User supplies a prompt in the form of a URL (edit as needed or integrate your own input method)\n    user_input_url = \"https://mozilla-ai.github.io/any-agent/agents/\"  # Example URL, change as necessary\n    prompt = f\"Summarize the main textual content from this webpage: {user_input_url}\"\n\n    agent_trace = agent.run(prompt=prompt)\n\n    # Save agent trace as JSON\n    with open(\"generated_workflows/latest/agent_eval_trace.json\", \"w\", encoding=\"utf-8\") as f:\n        f.write(agent_trace.model_dump_json(indent=2))\n```",
  "run_instructions": "```markdown\n# Webpage Content Summarizer Agent: Setup & Usage\n\n## 1. Environment Variables\n- Create a `.env` file in the project root.\n- **No mandatory secret keys or credentials** are required for this workflow unless your OpenAI API access is handled externally (recommended).\n- If you need to set custom OpenAI API keys, add lines like:\n  ```\n  OPENAI_API_KEY=sk-...your-key...\n  ```\n  (Ensure your OpenAI credentials are otherwise properly available for any-agent/OpenAI SDK to function.)\n\n## 2. Setup Environment\n- Install [Mamba](https://mamba.readthedocs.io/en/latest/installation.html) if not already installed.\n- Create and activate a Python 3.11 environment:\n  ```sh\n  mamba create -n anyagent-summarizer python=3.11 -y\n  mamba activate anyagent-summarizer\n  ```\n\n## 3. Install Dependencies\n- Place the provided dependencies in a `requirements.txt` file.\n- Install all dependencies:\n  ```sh\n  pip install -r requirements.txt\n  ```\n\n## 4. Directory Preparation\n- Ensure the directory `generated_workflows/latest/` exists:\n  ```sh\n  mkdir -p generated_workflows/latest\n  ```\n\n## 5. Run the Agent\n- Execute the agent script:\n  ```sh\n  python agent.py\n  ```\n- The agent's full execution trace and output will be saved to `generated_workflows/latest/agent_eval_trace.json`.\n\n---\n**Tip:**\n- To summarize a different webpage, change the `user_input_url` variable inside `agent.py` accordingly, or adjust the code to accept user input.\n```",
  "dependencies": "```\nany-agent[all]\ndotenv\npydantic>=2.0.0\n```"
}